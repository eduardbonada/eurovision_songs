{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Eurovision using Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import json\n",
    "import pandas as pd\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "from patsy import dmatrices, dmatrix\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "491 tracks read\n"
     ]
    }
   ],
   "source": [
    "# read songs info from file\n",
    "tracks = []\n",
    "track_ids_read = []\n",
    "if os.path.isfile('available_tracks_info.json'):\n",
    "    json_data=open('available_tracks_info.json').read()\n",
    "    tracks = json.loads(json_data)\n",
    "    track_ids_read = [t['id'] for t in tracks]\n",
    "    print(\"{} tracks read\".format(len(track_ids_read)))\n",
    "\n",
    "# Create pandas dataframe\n",
    "tracks_df = pd.DataFrame.from_dict(tracks).drop(['analysis_url', 'track_href', 'uri', 'id'], 1)\n",
    "tracks_df[['Rank','Points']] = tracks_df[['Rank','Points']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression predicting Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 343\n",
      "X_test:  148\n",
      "y_train: 343\n",
      "y_test:  148\n",
      "\n",
      "Score train: 0.11324834858373589\n",
      "Score test:  -0.02123805796681366\n",
      "\n",
      "            features     coefs\n",
      "0          intercept  0.000000\n",
      "1       acousticness -1.456328\n",
      "2       danceability  1.088850\n",
      "3             energy -0.538561\n",
      "4   instrumentalness  0.533639\n",
      "5                key -0.076811\n",
      "6           liveness -0.119143\n",
      "7           loudness  0.931903\n",
      "8               mode -0.576098\n",
      "9        speechiness -0.203410\n",
      "10             tempo -0.053443\n",
      "11    time_signature -0.053582\n",
      "12           valence -1.731178\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4.426211</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.267160</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.877629</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.888678</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.915975</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.152553</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6.165789</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6.251600</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.484445</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.801565</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>7.024667</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.042116</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>7.070247</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.180577</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>7.398875</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.418451</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>7.466428</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>7.494596</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>7.553045</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.563391</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>7.723167</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>7.788082</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.809615</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7.934485</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>8.088277</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.105938</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8.180396</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>8.239771</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8.312651</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.316120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>12.137558</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.247765</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12.254385</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>12.386540</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>12.406049</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>12.408907</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>12.429758</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>12.442429</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>12.453021</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.525858</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>12.549290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.562637</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>12.590277</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>12.748109</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>12.798715</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>13.005674</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>13.018826</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.053075</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13.097813</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>13.112640</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>13.360981</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>13.486566</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13.947389</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>14.242481</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>14.255862</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>14.269758</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>14.421342</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>14.469815</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>14.784303</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>17.054273</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted  real\n",
       "44    4.426211  15.0\n",
       "29    5.267160   8.0\n",
       "92    5.877629   1.0\n",
       "0     5.888678   9.0\n",
       "28    5.915975   3.0\n",
       "27    6.152553   7.0\n",
       "69    6.165789  10.0\n",
       "56    6.251600   1.0\n",
       "17    6.484445  14.0\n",
       "4     6.801565   1.0\n",
       "64    7.024667   2.0\n",
       "12    7.042116   7.0\n",
       "120   7.070247   1.0\n",
       "20    7.180577   7.0\n",
       "42    7.398875   4.0\n",
       "122   7.418451  15.0\n",
       "136   7.466428   6.0\n",
       "84    7.494596   7.0\n",
       "81    7.553045  18.0\n",
       "37    7.563391  18.0\n",
       "101   7.723167  10.0\n",
       "89    7.788082   2.0\n",
       "18    7.809615   6.0\n",
       "26    7.934485  22.0\n",
       "63    8.088277  17.0\n",
       "5     8.105938   8.0\n",
       "23    8.180396  12.0\n",
       "140   8.239771  13.0\n",
       "21    8.312651  11.0\n",
       "1     8.316120   1.0\n",
       "..         ...   ...\n",
       "83   12.137558  18.0\n",
       "14   12.247765   6.0\n",
       "35   12.254385  13.0\n",
       "133  12.386540   9.0\n",
       "16   12.406049  16.0\n",
       "121  12.408907  19.0\n",
       "76   12.429758   5.0\n",
       "144  12.442429  12.0\n",
       "59   12.453021   2.0\n",
       "9    12.525858  11.0\n",
       "141  12.549290   1.0\n",
       "15   12.562637  18.0\n",
       "30   12.590277  16.0\n",
       "46   12.748109  20.0\n",
       "94   12.798715   4.0\n",
       "128  13.005674  24.0\n",
       "131  13.018826  16.0\n",
       "7    13.053075   7.0\n",
       "32   13.097813  24.0\n",
       "135  13.112640  23.0\n",
       "108  13.360981  22.0\n",
       "43   13.486566  11.0\n",
       "31   13.947389  12.0\n",
       "36   14.242481  19.0\n",
       "118  14.255862   6.0\n",
       "87   14.269758   5.0\n",
       "78   14.421342  12.0\n",
       "53   14.469815   7.0\n",
       "65   14.784303   6.0\n",
       "134  17.054273  12.0\n",
       "\n",
       "[148 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the features to analyze in the model\n",
    "features = ['acousticness', 'danceability', 'energy',\\\n",
    "           'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\\\n",
    "           'speechiness', 'tempo', 'time_signature', 'valence']\n",
    "features_string = ' + '.join(features)\n",
    "\n",
    "# create input matrix and outut array\n",
    "y, X = dmatrices('Rank ~ {}'.format(features_string), tracks_df, return_type = 'dataframe')\n",
    "\n",
    "# sklearn split\n",
    "X_train, X_test, y_train, y_test = train_test_split(StandardScaler().fit_transform(X), y, test_size=0.3, random_state=randint(0,1000))\n",
    "print('X_train: {}\\nX_test:  {}\\ny_train: {}\\ny_test:  {}\\n'.format(len(X_train),len(X_test),len(y_train),len(y_test)))\n",
    "\n",
    "# Linear Regression model with sklearn\n",
    "model = LinearRegression(fit_intercept = True, normalize = False, copy_X=True)\n",
    "regressor = model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# print results\n",
    "print(\"Score train: {}\".format(regressor.score(X_train, y_train)))\n",
    "print(\"Score test:  {}\\n\".format(regressor.score(X_test, y_test)))\n",
    "\n",
    "# print feature relationship\n",
    "features_tmp = np.insert(features,0,'intercept')\n",
    "print(pd.DataFrame(list(zip(features_tmp, model.coef_.ravel())), columns=['features','coefs']))\n",
    "\n",
    "# predict test\n",
    "pd.DataFrame(list(zip(model.predict(X_test), y_test.values.ravel())), columns=['predicted','real']).sort_values('predicted', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification of TopN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create label 'isTopN'\n",
    "tracks_df['isTop5'] = tracks_df.apply(lambda r: 1 if r['Rank']<=5 else 0, axis=1)\n",
    "tracks_df['isTop10'] = tracks_df.apply(lambda r: 1 if r['Rank']<=10 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 392\n",
      "X_test:  99\n",
      "y_train: 392\n",
      "y_test:  99\n",
      "\n",
      "Classification performance metrics\n",
      "Accuracy: 0.6565656565656566\n",
      "F1 Score: 0.15000000000000002\n",
      "ROC AUC:  0.5151515151515151\n",
      "\n",
      "            features     coefs\n",
      "0          intercept -0.452529\n",
      "1       acousticness  0.356438\n",
      "2       danceability -0.008212\n",
      "3             energy  0.191979\n",
      "4   instrumentalness -0.134044\n",
      "5                key  0.021536\n",
      "6           liveness -0.134357\n",
      "7           loudness -0.275767\n",
      "8               mode  0.094918\n",
      "9        speechiness  0.084129\n",
      "10             tempo  0.136408\n",
      "11    time_signature -0.029344\n",
      "12           valence  0.111954\n",
      "\n",
      "Euroscore performance metrics\n",
      "Accuracy Top 5: 55%\n",
      "Accuracy Top 10: 75%\n"
     ]
    }
   ],
   "source": [
    "isTopN = 'isTop5'\n",
    "\n",
    "# set the features to analyze in the model\n",
    "features = ['acousticness', 'danceability', 'energy',\\\n",
    "           'instrumentalness', 'key', 'liveness', 'loudness', 'mode',\\\n",
    "           'speechiness', 'tempo', 'time_signature', 'valence']\n",
    "features_string = ' + '.join(features)\n",
    "\n",
    "# create the standardscaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# create input matrix and outut array\n",
    "y, X = dmatrices('{} ~ {}'.format(isTopN, features_string), tracks_df, return_type = 'dataframe')\n",
    "\n",
    "# normalize features\n",
    "X_norm = pd.DataFrame(scaler.fit_transform(X))\n",
    "X_norm[0] = 1 # set intercept back to 1 (scaler sets it to 0 because of 0 variance)\n",
    "\n",
    "# sklearn split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2, random_state=randint(0,1000))\n",
    "print('X_train: {}\\nX_test:  {}\\ny_train: {}\\ny_test:  {}\\n'.format(len(X_train),len(X_test),len(y_train),len(y_test)))\n",
    "\n",
    "# Linear Regression model with sklearn\n",
    "regularization = 0.001\n",
    "model = LogisticRegression(fit_intercept = True, C = 1/regularization)\n",
    "regressor = model.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "# predict test\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# print scores\n",
    "print('Classification performance metrics')\n",
    "print('Accuracy: {}'.format(metrics.accuracy_score(y_test, y_test_pred)))\n",
    "print('F1 Score: {}'.format(metrics.f1_score(y_test, y_test_pred)))\n",
    "print('ROC AUC:  {}\\n'.format(metrics.roc_auc_score(y_test, y_test_pred)))\n",
    "\n",
    "# print feature relationship\n",
    "features_tmp = np.insert(features,0,'intercept')\n",
    "print(pd.DataFrame(list(zip(features_tmp, model.coef_.ravel())), columns=['features','coefs']))\n",
    "\n",
    "# compute the new predicted score using the feature weights modeled in Logistic Regression\n",
    "tracks_df['euroscore'] = np.dot(X_norm, model.coef_.T)\n",
    "\n",
    "# Ranking\n",
    "print('\\nEuroscore performance metrics')\n",
    "print(\"Accuracy Top 5: {}%\".format(5*tracks_df.sort_values(by = 'euroscore', ascending = False)[0:20]['isTop5'].sum()))\n",
    "print(\"Accuracy Top 10: {}%\".format(5*tracks_df.sort_values(by = 'euroscore', ascending = False)[0:20]['isTop10'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict how artists songs would perform in Eurovision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spotify wrapper object\n",
    "from spotify_wrapper import SpotifyWrapper\n",
    "sp = SpotifyWrapper(client_id = '9b23e599c83f45d9a93e6559d79b3f4a', \n",
    "                    client_secret = '710a69f7a7984a6c9c71c1682c46d7b5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 artists read - 9646 tracks read\n"
     ]
    }
   ],
   "source": [
    "# read artists info to compare to eurovision songs\n",
    "artists_tracks_full_info = []\n",
    "artists_read = []\n",
    "if os.path.isfile('../festivals2018/tracks_full_info.json'):\n",
    "    json_data=open('../festivals2018/tracks_full_info.json').read()\n",
    "    artists_tracks_full_info = json.loads(json_data)\n",
    "    artists_read = set([sp.remove_accents(a['artist_name'].lower()) for a in artists_tracks_full_info])\n",
    "    print(\"{} artists read - {} tracks read\".format(len(artists_read),len(artists_tracks_full_info)))\n",
    "\n",
    "# Create pandas dataframe\n",
    "artists_tracks_df = pd.DataFrame.from_dict(artists_tracks_full_info).drop(['analysis_url', 'album_id', 'artist_id', 'track_href', 'uri', 'type', 'id'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/.local/lib/python3.5/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "/home/eduard/.local/lib/python3.5/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# create a dataframe with the songs to predict\n",
    "#songs_to_predict = artists_tracks_df[artists_tracks_df['artist_name']=='Pau Vallvé']\n",
    "songs_to_predict = artists_tracks_df[artists_tracks_df['artist_name']=='Bon Iver']\n",
    "\n",
    "# create features matrix\n",
    "X_new = dmatrix('{}'.format(features_string), songs_to_predict, return_type = 'dataframe')\n",
    "\n",
    "# normalize features\n",
    "X_new_norm = pd.DataFrame(scaler.transform(X_new))\n",
    "X_new_norm[0] = 1 # set intercept back to 1 (scaler sets it to 0 because of 0 variance)\n",
    "\n",
    "# preict topN\n",
    "songs_to_predict[isTopN] = regressor.predict(X_new_norm)\n",
    "\n",
    "# compute the new predicted score using the feature weights modeled in Logistic Regression\n",
    "songs_to_predict['euroscore'] = np.dot(X_new_norm, model.coef_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_name</th>\n",
       "      <th>name</th>\n",
       "      <th>isTop10</th>\n",
       "      <th>euroscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>22, A Million</td>\n",
       "      <td>00000 Million</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.675253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>Bon Iver</td>\n",
       "      <td>Wash.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.334506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>For Emma, Forever Ago</td>\n",
       "      <td>Lump Sum</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.332698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>For Emma, Forever Ago</td>\n",
       "      <td>Flume</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.189181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>Bon Iver</td>\n",
       "      <td>Michicant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.062729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>22, A Million</td>\n",
       "      <td>22 (OVER S∞∞N)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>For Emma, Forever Ago</td>\n",
       "      <td>Creature Fear</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.954269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>For Emma, Forever Ago</td>\n",
       "      <td>Blindsided</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.938964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>For Emma, Forever Ago</td>\n",
       "      <td>re:stacks</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.903483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>22, A Million</td>\n",
       "      <td>____45_____</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 album_name            name  isTop10  euroscore\n",
       "1912          22, A Million   00000 Million      1.0   1.675253\n",
       "1919               Bon Iver           Wash.      1.0   1.334506\n",
       "1924  For Emma, Forever Ago        Lump Sum      1.0   1.332698\n",
       "1923  For Emma, Forever Ago           Flume      1.0   1.189181\n",
       "1917               Bon Iver       Michicant      1.0   1.062729\n",
       "1903          22, A Million  22 (OVER S∞∞N)      1.0   0.978877\n",
       "1928  For Emma, Forever Ago   Creature Fear      1.0   0.954269\n",
       "1927  For Emma, Forever Ago      Blindsided      1.0   0.938964\n",
       "1931  For Emma, Forever Ago       re:stacks      1.0   0.903483\n",
       "1911          22, A Million     ____45_____      1.0   0.899456"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_to_predict[['album_name', 'name', isTopN, 'euroscore']].sort_values(by=[isTopN, 'euroscore'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Eurovision 2018 topN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv with all songs in finals \n",
    "import csv\n",
    "songs = []\n",
    "with open('2018_songs_with_ids_orig.csv') as csv_file:\n",
    "    songs = [{k: v for k, v in row.items()} for row in csv.DictReader(csv_file, skipinitialspace=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of songs with id: 0\n",
      "0 FOUND 1 1: Aisel - X My Heart | Aisel - X My Heart\n",
      "1 FOUND 1 1: Ari Ólafsson - Our Choice | Ari Ólafsson - Our Choice\n",
      "2 FOUND 1 1: Eugent Bushpepa - Mall | Eugent Bushpepa - Mall\n",
      "3 FOUND 1 1: Sennek - A Matter of Time | Sennek - A Matter Of Time\n",
      "4 FOUND 1 1: Mikolas Josef - Lie to Me | Mikolas Josef - Lie to Me\n",
      "5 FOUND 1 1: Ieva Zasimauskaitė - When We're Old | Ieva Zasimauskaitė - When We're Old\n",
      "6 FOUND 1 1: Netta - Toy | Netta - Toy\n",
      "7 FOUND 1 0: Alekseev - Forever | Alekseev - Forever - Eurovision Version\n",
      "8 FOUND 1 1: Elina Nechayeva - La forza | Elina Nechayeva - La Forza\n",
      "9 FOUND 1 0: Equinox - Bones | Equinox - Bones - Studio Version\n",
      "10 FOUND 1 0: Eye Cue - Lost and Found | Eye Cue - Lost & Found\n",
      "11 FOUND 1 1: Franka - Crazy | Franka - Crazy\n",
      "12 FOUND 1 1: Cesár Sampson - Nobody but You | Cesar Sampson - Nobody But You\n",
      "13 FOUND 1 1: Yianna Terzi - Oniro mou | Yianna Terzi - Oniro Mou\n",
      "14 FOUND 1 1: Saara Aalto - Monsters | Saara Aalto - Monsters\n",
      "15 FOUND 1 1: Sevak Khanagyan - Qami | Sevak Khanagyan - Qami\n",
      "16 FOUND 1 1: Zibbz - Stones | ZiBBZ - Stones\n",
      "17 FOUND 1 1: Ryan O'Shaughnessy - Together | Ryan O'Shaughnessy - Together\n",
      "18 FOUND 1 1: Eleni Foureira - Fuego | Eleni Foureira - Fuego\n",
      "19 FOUND 1 1: Alexander Rybak - That's How You Write a Song | Alexander Rybak - That's How You Write A Song\n",
      "20 FOUND 1 1: The Humans - Goodbye | The Humans - Goodbye\n",
      "21 FOUND 1 1: Sanja Ilić & Balkanika - Nova deca | Sanja Ilic & Balkanika - Nova Deca\n",
      "22 FOUND 1 0: Jessika - Who We Are | Jessika - Who We Are (feat. Jenifer Brening)\n",
      "23 FOUND 1 1: Rasmussen - Higher Ground | Rasmussen - Higher Ground\n",
      "24 FOUND 1 1: Julia Samoylova - I Won't Break | Julia Samoylova - I Won't Break\n",
      "25 FOUND 1 1: DoReDos - My Lucky Day | DoReDoS - My Lucky Day\n",
      "26 FOUND 1 0: Waylon - Outlaw in 'Em | Waylon - Outlaw In 'Em - Single Edit\n",
      "27 FOUND 1 1: Jessica Mauboy - We Got Love | Jessica Mauboy - We Got Love\n",
      "28 FOUND 1 1: Ethno - Jazz Band Iriao - For You | Ethno - Jazz Band Iriao - For You\n",
      "29 FOUND 1 1: Gromee - Light Me Up | Gromee - Light Me Up\n",
      "30 FOUND 1 1: Christabelle - Taboo | Christabelle - Taboo\n",
      "31 FOUND 1 0: AWS - Viszlát nyár | Aws - Viszlát nyár (Eurovision Song Contest 2018)\n",
      "32 FOUND 1 1: Laura Rizzotto - Funny Girl | Laura Rizzotto - Funny Girl\n",
      "33 FOUND 1 1: Benjamin Ingrosso - Dance You Off | Benjamin Ingrosso - Dance You Off\n",
      "34 FOUND 1 1: Vanja Radovanović - Inje | Vanja Radovanović - Inje\n",
      "35 FOUND 1 0: Lea Sirk - Hvala ne! | Lea Sirk - Hvala Ne\n",
      "36 FOUND 1 1: Mélovin - Under the Ladder | MÉLOVIN - Under the Ladder\n",
      "37 FOUND 1 1: Cláudia Pascoal - O jardim | Cláudia Pascoal - O Jardim\n",
      "38 FOUND 1 1: Madame Monsieur - Mercy | Madame Monsieur - Mercy\n",
      "39 FOUND 1 1: Michael Schulte - You Let Me Walk Alone | Michael Schulte - You Let Me Walk Alone\n",
      "40 FOUND 1 1: Ermal Meta - Non mi avete fatto niente | Ermal Meta - Non mi avete fatto niente\n",
      "41 FOUND 1 1: Amaia Romero - Tu canción | Amaia Romero - Tu Canción\n",
      "42 FOUND 1 1: SuRie - Storm | SuRie - Storm\n"
     ]
    }
   ],
   "source": [
    "# count songs with id\n",
    "count_songs_with_id = sum([ (1 if s['id']!='' else 0) for s in songs])\n",
    "print('Count of songs with id:',count_songs_with_id)\n",
    "\n",
    "# get spotify song ids\n",
    "for i,s in enumerate(songs):\n",
    "        \n",
    "    # only search those songs without id\n",
    "    if s['id']=='':\n",
    "        \n",
    "        # search song info\n",
    "        song_info = sp.search_song(s['Artist'], s['Song'])\n",
    "        \n",
    "        # process received info\n",
    "        if song_info == None:\n",
    "            print('{} NOT FOUND: {} - {}'.format(i, s['Artist'], s['Song']))\n",
    "\n",
    "        else:\n",
    "            \n",
    "            # sanity checks\n",
    "            check_artist = 1 if sp.remove_accents(s['Artist'].lower()) == sp.remove_accents(song_info['artists'][0]['name'].lower()) else 0\n",
    "            check_title = 1 if sp.remove_accents(s['Song'].lower()) == sp.remove_accents(song_info['name'].lower()) else 0\n",
    "            \n",
    "            print('{} FOUND {} {}: {} - {} | {} - {}'.format(i, check_artist, check_title, \n",
    "                                                            s['Artist'], s['Song'], \n",
    "                                                            song_info['artists'][0]['name'], song_info['name']))\n",
    "\n",
    "            # store id in original object dictionary\n",
    "            s['id'] = song_info['id']\n",
    "\n",
    "            # store song with id in csv file\n",
    "            keys = s.keys()\n",
    "            with open('2018_songs_with_ids.csv', 'w') as output_file:\n",
    "                w = csv.DictWriter(output_file, keys)\n",
    "                w.writeheader()\n",
    "                w.writerows(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv with all songs from 2018 (already with ids)\n",
    "import csv\n",
    "songs = []\n",
    "with open('2018_songs_with_ids.csv') as csv_file:\n",
    "    songs = [{k: v for k, v in row.items()} for row in csv.DictReader(csv_file, skipinitialspace=True)]\n",
    "    \n",
    "# create dataframe\n",
    "songs_df = pd.DataFrame(songs)\n",
    "available_songs = songs_df[songs_df['id'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Api Call 0 from 0 to 19\n",
      "Api Call 1 from 20 to 39\n",
      "Api Call 2 from 40 to 42\n"
     ]
    }
   ],
   "source": [
    "# get audio features of songs\n",
    "songs_full_info = list(available_songs.T.to_dict().values()) # list of dicts - dicts must have field 'id'\n",
    "songs_full_info = sp.get_audio_features_of_lots_of_tracks(songs_full_info)\n",
    "\n",
    "# store songs full info into file\n",
    "with open('2018_songs_info.json', 'w') as fp:\n",
    "    json.dump(songs_full_info, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 songs read\n"
     ]
    }
   ],
   "source": [
    "# read from file if already downloaded\n",
    "songs_full_info = []\n",
    "track_ids_read = []\n",
    "if os.path.isfile('2018_songs_info.json'):\n",
    "    json_data=open('2018_songs_info.json').read()\n",
    "    songs_full_info = json.loads(json_data)\n",
    "    track_ids_read = [t['id'] for t in songs_full_info]\n",
    "    print(\"{} songs read\".format(len(track_ids_read)))\n",
    "    \n",
    "# Create pandas dataframe\n",
    "songs_df = pd.DataFrame.from_dict(songs_full_info).drop(['analysis_url', 'track_href', 'uri', 'id'], 1)\n",
    "songs_df[['Rank','Points']] = songs_df[['Rank','Points']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the songs to predict\n",
    "songs_to_predict = songs_df\n",
    "\n",
    "# create features matrix\n",
    "X_new = dmatrix('{}'.format(features_string), songs_to_predict, return_type = 'dataframe')\n",
    "\n",
    "# normalize features\n",
    "X_new_norm = pd.DataFrame(scaler.transform(X_new))\n",
    "X_new_norm[0] = 1 # set intercept back to 1 (scaler sets it to 0 because of 0 variance)\n",
    "\n",
    "# preict topN\n",
    "songs_to_predict[isTopN] = regressor.predict(X_new_norm)\n",
    "\n",
    "# compute the new predicted score using the feature weights modeled in Logistic Regression\n",
    "songs_to_predict['euroscore'] = np.dot(X_new_norm, model.coef_.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>isTop5</th>\n",
       "      <th>euroscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.410783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Germany</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.168722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Spain</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.086067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.127580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Norway</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.372494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Albania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.476215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Italy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.549892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.650181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Georgia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.653562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Slovenia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.698133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Latvia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.724687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.728882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.778887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.789122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Macedonia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.801520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Azerbaijan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.805373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Hungary</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.842347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>San Marino</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.843984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.853558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Belarus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.866869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Israel</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.891473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.893537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czech Republic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.893750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Poland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.939911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Greece</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.957609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.976700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.987440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.004066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Serbia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.025175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Australia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.032814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.053987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.098075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Russia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.138066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Romania</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.188569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Malta</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.203275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Finland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.224777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.225405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cyprus</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.310648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Armenia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.326356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Austria</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.447966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Montenegro</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.462639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>France</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.647854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Country  isTop5  euroscore\n",
       "5        Lithuania     0.0   0.410783\n",
       "39         Germany     0.0   0.168722\n",
       "17         Ireland     0.0   0.002767\n",
       "41           Spain     0.0  -0.086067\n",
       "37        Portugal     0.0  -0.127580\n",
       "19          Norway     0.0  -0.372494\n",
       "2          Albania     0.0  -0.476215\n",
       "40           Italy     0.0  -0.549892\n",
       "33          Sweden     0.0  -0.650181\n",
       "28         Georgia     0.0  -0.653562\n",
       "35        Slovenia     0.0  -0.698133\n",
       "32          Latvia     0.0  -0.724687\n",
       "8          Estonia     0.0  -0.728882\n",
       "42  United Kingdom     0.0  -0.778887\n",
       "1          Iceland     0.0  -0.789122\n",
       "10       Macedonia     0.0  -0.801520\n",
       "0       Azerbaijan     0.0  -0.805373\n",
       "31         Hungary     0.0  -0.842347\n",
       "22      San Marino     0.0  -0.843984\n",
       "36         Ukraine     0.0  -0.853558\n",
       "7          Belarus     0.0  -0.866869\n",
       "6           Israel     0.0  -0.891473\n",
       "25         Moldova     0.0  -0.893537\n",
       "4   Czech Republic     0.0  -0.893750\n",
       "29          Poland     0.0  -0.939911\n",
       "13          Greece     0.0  -0.957609\n",
       "9         Bulgaria     0.0  -0.976700\n",
       "26     Netherlands     0.0  -0.987440\n",
       "11         Croatia     0.0  -1.004066\n",
       "21          Serbia     0.0  -1.025175\n",
       "27       Australia     0.0  -1.032814\n",
       "23         Denmark     0.0  -1.053987\n",
       "16     Switzerland     0.0  -1.098075\n",
       "24          Russia     0.0  -1.138066\n",
       "20         Romania     0.0  -1.188569\n",
       "30           Malta     0.0  -1.203275\n",
       "14         Finland     0.0  -1.224777\n",
       "3          Belgium     0.0  -1.225405\n",
       "18          Cyprus     0.0  -1.310648\n",
       "15         Armenia     0.0  -1.326356\n",
       "12         Austria     0.0  -1.447966\n",
       "34      Montenegro     0.0  -1.462639\n",
       "38          France     0.0  -1.647854"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs_to_predict[['Country', isTopN, 'euroscore']].sort_values(by=[isTopN, 'euroscore'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
